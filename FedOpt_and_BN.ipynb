{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e02c1757-72bc-42e0-8359-6a61a1956e79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Federated optimization and some batch normalization strategies. \n",
    "``FedOpt`` (Reddi et al., 2020) is a generalisation of the baseline algorithm `FedAvg` (McMahan et al.). `FedOpt` rewrites the update rule of `FedAvg` and thus allows the usage of gradient descent based optimizers for the server update. More precisely, `FedAvg` update rule is the average of all the clients parameters : \n",
    "\n",
    "\\begin{align}\n",
    "    x_{t+1} = \\frac{1}{|\\mathcal{S}|} \\sum_{i \\in \\mathcal{S}} x_i^t\n",
    "\\end{align}\n",
    "\n",
    "With $x$ the global model's parameters ($x_i$ client $i$'s parameters)  $t$ being the current round and $\\mathcal{S}$ the set of sampled clients.\n",
    "\n",
    "This update rule can be written as : \n",
    "\n",
    "\\begin{align} \n",
    "    x_{t+1} = x_t - \\frac{1}{|\\mathcal{S}|} \\sum_{i \\in \\mathcal{S}} (x_t - x_i^t)\n",
    "\\end{align}\n",
    "\n",
    "which is somewhat analogous to gradient descent based optimization methods if we added a learning rate. Recall `SGD` update rule takes the form : \n",
    "\\begin{align}\n",
    "    x_{t+1} = x_t - \\eta \\nabla f_t(x_t) \n",
    "\\end{align} \n",
    "\n",
    "with $\\eta$ being the learning rate and $f_t(x_t)$ a loss function at time step $t$. Let $\\Delta_i^t = x_i^t - x_t$ represent the difference between a client and the current global model and $\\Delta_t = \\frac{1}{|\\mathcal{S}|} \\sum_{i \\in \\mathcal{S}} \\Delta_i^t$ represent the average of the local clients differences. Considering $\\Delta_t$ as pseudo gradient, we can apply `SGD` (or any gradient based optimizer) to update the global model at each rounds. \n",
    "Hence applying `SGD` with $-\\Delta_t$ and $\\eta = 1$ is equivalent to `FedAvg` : \n",
    "\n",
    "\\begin{align}\n",
    "    x_{t+1} & = x_t - 1 \\times - \\Delta_t  \\\\\n",
    "            & = x_t + \\Delta_t \\\\\n",
    "            &= x_t + \\frac{1}{|S|} \\sum_{i \\in S} (x_i^t - x_t)) \\\\\n",
    "            &= \\frac{1}{|S|} \\sum_{i \\in S} x_i^t \\tag{1} \n",
    "\\end{align} \n",
    "\n",
    "**Aggregation strategy** : instead of simply averaging the weights, one can compute a weighted average using client's local dataset sizes. \n",
    "\n",
    "\\begin{align}\n",
    "    x_{t+1} = x_t + \\frac{\\sum_{i \\in \\mathcal{S}} p_i \\Delta_i^t}{\\sum_{i \\in \\mathcal{S}} p_i} \\tag{2}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78abe9e8-c6e2-4576-852a-ea8ca32d679a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccbd8aec-9298-4e93-9d90-b8b303556c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\laurent.vouriot\\\\Documents\\\\Laurent\\\\working\\\\AntibioStat\\\\notebooks\\\\FL'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bddf26d3-380e-4643-bf6a-0c2bc32ea3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laurent.vouriot\\Documents\\Laurent\\working\\AntibioStat\n"
     ]
    }
   ],
   "source": [
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca2a8a92-d9f5-4f67-8da2-cece76ca9054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"src\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0177c87-7dac-484d-ae41-f4bb2416bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e00f00c9-2294-43cd-82f6-64bb375f1109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2066b98fe50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad7a1584-fa0e-4a97-b5ae-e0246ac8dc45",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "One of the most significant problems in the Federated Learning field, is the heterogenous data distribution clients. For our simulation, we will use MNIST data split in a non-IID fashion, generating a 2-silo non-IID dataset where each silo contains only specific classes.\n",
    "\n",
    "![IID vs non-IID data](figs/IID-vs-non-IID.png \"IID vs non-IID data\")\n",
    "\n",
    "*from Wireless for Machine Learning: a Survey, Hellstr√∂m et al. 2020*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82ab3664-2ff2-4569-9707-8def2d0fe55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "def get_class_indices(dataset, class_label):\n",
    "    return [i for i, (x, y) in enumerate(dataset) if y == class_label]\n",
    "\n",
    "silo_1_classes = [0, 1, 2, 3, 4]\n",
    "silo_2_classes = [5, 6, 7, 8, 9]\n",
    "\n",
    "silo_1_indices = []\n",
    "silo_2_indices = []\n",
    "\n",
    "for cls in silo_1_classes:\n",
    "    silo_1_indices.extend(get_class_indices(mnist_train, cls))\n",
    "\n",
    "for cls in silo_2_classes:\n",
    "    silo_2_indices.extend(get_class_indices(mnist_train, cls))\n",
    "\n",
    "silo_1_data = Subset(mnist_train, silo_1_indices)\n",
    "silo_2_data = Subset(mnist_train, silo_2_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "106f3d29-38d1-4b1d-a330-28505b85dc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30596, 29404)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(silo_1_data), len(silo_2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "965545d3-3f6b-4ed2-844b-8fe0d7e16c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.random.choice(range(len(silo_2_data)), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68eea3f8-b163-421d-8792-f7dd04f2827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_silo_1 = silo_1_data.__getitems__(random_indices)\n",
    "items_silo_2 = silo_2_data.__getitems__(random_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7df1235-5bc9-4431-9ca8-93111004510b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 10, figsize=(15, 6))\n",
    "for i, (image, label) in enumerate(items_silo_1):\n",
    "    axs[0, i].imshow(image.squeeze(), cmap='gray') \n",
    "    axs[0, i].axis('off')  \n",
    "\n",
    "for i, (image, label) in enumerate(items_silo_2):\n",
    "    axs[1, i].imshow(image.squeeze(), cmap='gray')  \n",
    "    axs[1, i].axis('off') \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f0f96-b75d-4fb5-968e-b07fd85680c2",
   "metadata": {},
   "source": [
    "# Helpers functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b2727b6-015f-4fe4-b150-e2098f5c1224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_set):\n",
    "    model.eval()  \n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    test_loader = DataLoader(test_set, batch_size=128, shuffle=True)\n",
    "    \n",
    "    with torch.no_grad():  \n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.view(inputs.size(0), -1)  \n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total * 100  \n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ffa5294a-2522-4e0c-adb0-e4c4555ec21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp(algo, optim, verb=True, **kwargs):\n",
    "    \"\"\"\n",
    "        run a simulated federated learning experiment.\n",
    "    \"\"\"\n",
    "    global_model = Net()\n",
    "\n",
    "    client1 = Client('client1', Net(), silo_1_data)\n",
    "    client2 = Client('client2', Net(), silo_2_data)\n",
    "    \n",
    "    clients = [client1, client2] \n",
    "    \n",
    "    clientOpt = ClientOpt(epochs=kwargs['local_epochs'], lr=kwargs['client_lr'])\n",
    "    serverOpt = optim(global_model, kwargs['server_lr'])\n",
    "    global_model = algo(global_model, clients, clientOpt, serverOpt, kwargs['rounds'], verb=verb) \n",
    "    \n",
    "    results_g = evaluate_model(global_model, mnist_test)\n",
    "    results_c1 = evaluate_model(client1.model, mnist_test)\n",
    "    results_c2 = evaluate_model(client2.model, mnist_test)\n",
    "\n",
    "    return round(results_g), round(results_c1), round(results_c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ab732-29e5-4475-b8d1-29053a05f274",
   "metadata": {},
   "source": [
    "# Model\n",
    "for this task we use a basic neural network composed of a dense layer and batch norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aeac0599-5421-4876-9a02-6089def4b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(784, 128)  \n",
    "        self.bn1 = torch.nn.BatchNorm1d(128)  \n",
    "        self.fc2 = torch.nn.Linear(128, 10)  \n",
    "        self.relu = torch.nn.ReLU()  \n",
    "        self.softmax = torch.nn.Softmax(1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x) \n",
    "        x = self.relu(x) \n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ced29e-242d-4dc2-bdeb-8d4345e262d8",
   "metadata": {},
   "source": [
    "# The algorithm\n",
    "\n",
    "Below is the algorithm for FedOpt as defined in  [A Field Guide to Federated Optimization, Jianyu Wang et al. 2021](https://arxiv.org/abs/2107.06917)  which will serve as the basis for our implementation.\n",
    "\n",
    "![FedOpt](figs/FedOptAlg.PNG \"FedOpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "23c1e603-91f1-4fe1-837e-a5d874805aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client():\n",
    "    \"\"\"\n",
    "        Client class that embeds the model and the local dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, name, model, dataset):\n",
    "        self._name = name\n",
    "        self._model = model \n",
    "        self._dataset = dataset\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        return self._dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dff537a-a1f6-4571-8b0f-57589376bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientOpt():\n",
    "    \"\"\"\n",
    "        ClientOpt class, for local optimization of the client.\n",
    "    \"\"\"\n",
    "    def __init__(self, epochs=10, lr=0.001, batch_size=128, opt=torch.optim.SGD):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.opt = opt\n",
    "\n",
    "    def step(self, model, train, verb=True):\n",
    "        model.train()  \n",
    "        optimizer = self.opt(model.parameters(), lr=self.lr)\n",
    "        criterion = torch.nn.CrossEntropyLoss() \n",
    "\n",
    "        train_loader = DataLoader(train, batch_size=128, shuffle=True)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                \n",
    "                inputs = inputs.view(inputs.size(0), -1)  # Flatten input\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            avg_loss = running_loss / len(train_loader)\n",
    "            if verb:\n",
    "                print(f\"Epoch [{epoch+1}/{self.epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25098d86-dd91-4e75-b8b7-7d807eb1a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServerOpt():\n",
    "    \"\"\"\n",
    "        Base class for server optimization. As we will see later, different optimizers can \n",
    "        be used on server side.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, lr):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self, aggregated_delta, t=None):\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0891b55-83d6-4d5b-ad71-afc9d026ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServerSGD(ServerOpt):\n",
    "    \"\"\"\n",
    "        SGD optimizer, if lr=1, it is analogous to FedAvg.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, lr=1):\n",
    "        super().__init__(model, lr)\n",
    "        \n",
    "    def step(self, aggregated_delta, t=None):\n",
    "        for param_name, delta in aggregated_delta.items():\n",
    "            self.model.state_dict()[param_name].add_(self.lr * delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c49c0148-7917-49af-8850-b976adddbed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedOpt(global_model, clients, clientOpt, serverOpt, rounds, verb=True):\n",
    "    # retrieving datasets length for aggregation weights.\n",
    "    total_samples = sum([len(client.dataset) for client in clients])\n",
    "    clients_samples = {client.name : len(client.dataset) for client in clients}\n",
    "    for round in range(rounds):\n",
    "        if verb:\n",
    "            print(f'Round {round+1}')\n",
    "\n",
    "        # central datastructure to store local deltas.\n",
    "        clients_delta = {\n",
    "            client.name : {\n",
    "                name : torch.zeros_like(params,) for name, params in global_model.state_dict().items()\n",
    "            } for client in clients\n",
    "        } \n",
    "        \n",
    "        for client in clients:\n",
    "            client.model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "            clientOpt.step(client.model, client.dataset, verb=verb)\n",
    "            \n",
    "            # local changes\n",
    "            for name in client.model.state_dict().keys():\n",
    "                delta = client.model.state_dict()[name] - global_model.state_dict()[name]\n",
    "                clients_delta[client.name][name] = delta\n",
    "        \n",
    "        aggregated_delta = {name : torch.zeros_like(params) for name, params in global_model.state_dict().items()}\n",
    "\n",
    "        # aggregate local changes\n",
    "        for client_name, local_delta in clients_delta.items():\n",
    "            for param_name in local_delta.keys():\n",
    "                tmp =  (local_delta[param_name] * clients_samples[client_name] / total_samples)\n",
    "                tmp = tmp.to(aggregated_delta[param_name].dtype)\n",
    "                aggregated_delta[param_name] += tmp\n",
    "\n",
    "        # update global model\n",
    "        serverOpt.step(aggregated_delta, round+1)\n",
    "    \n",
    "    clients_delta.clear()\n",
    "    aggregated_delta.clear()\n",
    "\n",
    "    [client.model.load_state_dict(global_model.state_dict()) for client in clients]\n",
    "        \n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee604ef8-ad7e-4eb3-8b57-384d847fd3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Epoch [1/2], Loss: 2.3139\n",
      "Epoch [2/2], Loss: 2.2718\n",
      "Epoch [1/2], Loss: 2.2811\n",
      "Epoch [2/2], Loss: 2.2361\n",
      "Round 2\n",
      "Epoch [1/2], Loss: 2.2694\n",
      "Epoch [2/2], Loss: 2.1776\n",
      "Epoch [1/2], Loss: 2.2391\n",
      "Epoch [2/2], Loss: 2.1710\n",
      "Round 3\n",
      "Epoch [1/2], Loss: 2.1737\n",
      "Epoch [2/2], Loss: 2.0480\n",
      "Epoch [1/2], Loss: 2.1859\n",
      "Epoch [2/2], Loss: 2.1115\n",
      "Round 4\n",
      "Epoch [1/2], Loss: 2.0694\n",
      "Epoch [2/2], Loss: 1.9678\n",
      "Epoch [1/2], Loss: 2.1414\n",
      "Epoch [2/2], Loss: 2.0724\n",
      "Round 5\n",
      "Epoch [1/2], Loss: 1.9999\n",
      "Epoch [2/2], Loss: 1.9230\n",
      "Epoch [1/2], Loss: 2.1071\n",
      "Epoch [2/2], Loss: 2.0436\n",
      "Round 6\n",
      "Epoch [1/2], Loss: 1.9537\n",
      "Epoch [2/2], Loss: 1.8885\n",
      "Epoch [1/2], Loss: 2.0783\n",
      "Epoch [2/2], Loss: 2.0182\n",
      "Round 7\n",
      "Epoch [1/2], Loss: 1.9178\n",
      "Epoch [2/2], Loss: 1.8599\n",
      "Epoch [1/2], Loss: 2.0522\n",
      "Epoch [2/2], Loss: 1.9927\n",
      "Round 8\n",
      "Epoch [1/2], Loss: 1.8883\n",
      "Epoch [2/2], Loss: 1.8350\n",
      "Epoch [1/2], Loss: 2.0264\n",
      "Epoch [2/2], Loss: 1.9669\n",
      "Round 9\n",
      "Epoch [1/2], Loss: 1.8652\n",
      "Epoch [2/2], Loss: 1.8149\n",
      "Epoch [1/2], Loss: 2.0014\n",
      "Epoch [2/2], Loss: 1.9421\n",
      "Round 10\n",
      "Epoch [1/2], Loss: 1.8445\n",
      "Epoch [2/2], Loss: 1.7988\n",
      "Epoch [1/2], Loss: 1.9760\n",
      "Epoch [2/2], Loss: 1.9177\n",
      "global acc : 67, client1 acc : 67, client2 acc : 67\n"
     ]
    }
   ],
   "source": [
    "global_acc, client1_acc, client2_acc = exp(FedOpt, ServerSGD, verb=True, local_epochs=2, rounds=10, client_lr=0.001, server_lr=1)\n",
    "print(f'global acc : {global_acc}, client1 acc : {client1_acc}, client2 acc : {client2_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0253cb-c841-4cc5-93f2-9f9164d4c1fc",
   "metadata": {},
   "source": [
    "Results are not good, longer training and hyperparameters tuning should ameliorate the results. Also, local models are just copy of the global model, so no personalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4d5024-d28f-4375-bae6-d7eea9993341",
   "metadata": {},
   "source": [
    "# Some strategies with batch norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb5273a-12f5-406b-bc78-acb2093d7882",
   "metadata": {},
   "source": [
    "When using `FedOpt` with the server learning rate set to 1 (i.e., equivalent to `FedAvg`), all model parameters, including the local statistics of batch normalization layers, are averaged. This averaging can potentially slow down generalization, as the averaged batch statistics may erase the local specificities of each silo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b3789f-8afb-457d-bb69-c95ae403ebfa",
   "metadata": {},
   "source": [
    "## SiloBN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00757fb5-8128-4464-afb9-5f15ec9ce722",
   "metadata": {},
   "source": [
    "SiloBN ([Siloed federated learning for multi-centric histopathology datasets, Andreux et al. 2020](https://arxiv.org/abs/2008.07424))\n",
    "essentially shares the learnable parameters of batch normalization layers, while keeping the batch normalization statistics local to each client. This approach allows for somewhat personalized models that are better adapted to local datasets while still benefiting from shared general knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73db7e08-abb9-488d-b713-215baafad0a6",
   "metadata": {},
   "source": [
    "![SiloBN](figs/SiloBN.png \"SiloBN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec16c697-7378-4cfb-a148-0eda26556660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SiloBN(global_model, clients, clientOpt, serverOpt, rounds=50, verb=True):\n",
    "    \n",
    "    total_samples = sum([len(client.dataset) for client in clients])\n",
    "    clients_samples = {client.name : len(client.dataset) for client in clients}\n",
    "\n",
    "    # datastructure to keep in memory local bn statistics.\n",
    "    clients_local_bn_stats = {\n",
    "        client.name : {\n",
    "            param_name : params for param_name, params in client.model.named_buffers() \n",
    "        } for client in clients\n",
    "    }\n",
    "    for round in range(rounds):\n",
    "        if verb:\n",
    "            print(f'Round {round+1}')\n",
    "        \n",
    "        # local deltas.\n",
    "        clients_delta = {\n",
    "            client.name : {\n",
    "                name : torch.zeros_like(params) for name, params in global_model.named_parameters()\n",
    "            } for client in clients\n",
    "        } \n",
    "        \n",
    "        for client in clients:\n",
    "            if round != 0:\n",
    "                # loading global model and previous round's local bn statistics.\n",
    "                client.model.load_state_dict(global_model.state_dict(), strict=False)  \n",
    "                client.model.state_dict().update(clients_local_bn_stats[client.name])  \n",
    "            else:\n",
    "                client.model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "            clientOpt.step(client.model, client.dataset, verb=verb)\n",
    "           \n",
    "            # save local bn stats after local update\n",
    "            for name, stats in client.model.named_buffers():\n",
    "                clients_local_bn_stats[client.name][name].copy_(stats)\n",
    "            \n",
    "            # compute local changes, only on learnable parameters.\n",
    "            for name, _ in client.model.named_parameters():\n",
    "                delta = client.model.state_dict()[name] - global_model.state_dict()[name]\n",
    "                clients_delta[client.name][name] = delta\n",
    "\n",
    "        aggregated_delta = {name : torch.zeros_like(params) for name, params in global_model.named_parameters()}\n",
    "\n",
    "        # aggregate local changes.\n",
    "        for client_name, local_delta in clients_delta.items():\n",
    "            for param_name in local_delta.keys():\n",
    "                tmp =  (local_delta[param_name] * clients_samples[client_name] / total_samples)\n",
    "                tmp = tmp.to(aggregated_delta[param_name].dtype)\n",
    "                aggregated_delta[param_name] += tmp\n",
    "            \n",
    "        serverOpt.step(aggregated_delta, round+1)\n",
    "        \n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4737706a-8a48-43aa-88ef-8612981c0fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Epoch [1/2], Loss: 2.2753\n",
      "Epoch [2/2], Loss: 2.1979\n",
      "Epoch [1/2], Loss: 2.2871\n",
      "Epoch [2/2], Loss: 2.2481\n",
      "Round 2\n",
      "Epoch [1/2], Loss: 2.1953\n",
      "Epoch [2/2], Loss: 2.0995\n",
      "Epoch [1/2], Loss: 2.2558\n",
      "Epoch [2/2], Loss: 2.1952\n",
      "Round 3\n",
      "Epoch [1/2], Loss: 2.1120\n",
      "Epoch [2/2], Loss: 2.0158\n",
      "Epoch [1/2], Loss: 2.2121\n",
      "Epoch [2/2], Loss: 2.1343\n",
      "Round 4\n",
      "Epoch [1/2], Loss: 2.0400\n",
      "Epoch [2/2], Loss: 1.9525\n",
      "Epoch [1/2], Loss: 2.1618\n",
      "Epoch [2/2], Loss: 2.0774\n",
      "Round 5\n",
      "Epoch [1/2], Loss: 1.9805\n",
      "Epoch [2/2], Loss: 1.8964\n",
      "Epoch [1/2], Loss: 2.1114\n",
      "Epoch [2/2], Loss: 2.0299\n",
      "Round 6\n",
      "Epoch [1/2], Loss: 1.9288\n",
      "Epoch [2/2], Loss: 1.8520\n",
      "Epoch [1/2], Loss: 2.0687\n",
      "Epoch [2/2], Loss: 1.9957\n",
      "Round 7\n",
      "Epoch [1/2], Loss: 1.8845\n",
      "Epoch [2/2], Loss: 1.8170\n",
      "Epoch [1/2], Loss: 2.0355\n",
      "Epoch [2/2], Loss: 1.9707\n",
      "Round 8\n",
      "Epoch [1/2], Loss: 1.8503\n",
      "Epoch [2/2], Loss: 1.7922\n",
      "Epoch [1/2], Loss: 2.0092\n",
      "Epoch [2/2], Loss: 1.9502\n",
      "Round 9\n",
      "Epoch [1/2], Loss: 1.8240\n",
      "Epoch [2/2], Loss: 1.7698\n",
      "Epoch [1/2], Loss: 1.9870\n",
      "Epoch [2/2], Loss: 1.9325\n",
      "Round 10\n",
      "Epoch [1/2], Loss: 1.7986\n",
      "Epoch [2/2], Loss: 1.7499\n",
      "Epoch [1/2], Loss: 1.9682\n",
      "Epoch [2/2], Loss: 1.9162\n",
      "client1 acc : 64, client2 acc : 68\n"
     ]
    }
   ],
   "source": [
    "_, client1_acc, client2_acc = exp(SiloBN, ServerSGD, verb=True, local_epochs=2, rounds=10, client_lr=0.001, server_lr=1)\n",
    "print(f'client1 acc : {client1_acc}, client2 acc : {client2_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b149dcb0-98b4-4ee0-ae70-8810a418661b",
   "metadata": {},
   "source": [
    "Nothing better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e6645a-3db5-4335-af62-a7ac3a4d3427",
   "metadata": {},
   "source": [
    "## FedBN\n",
    "FedBN ([FedBN: Federated Learning on Non-IID Features via Local Batch Normalization, Li et al. 2021](https://arxiv.org/abs/2102.07623))is a federated learning approach where all batch normalization parameters, including the learnable parameters (e.g., scale and shift parameters) and the running statistics (e.g., mean and variance), are kept local to each client."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4b4c94-0dcb-4f2b-9f5f-2b958108d9fd",
   "metadata": {},
   "source": [
    "![FedBN](figs/FedBN.png \"FedBN algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a44b691b-5529-4f48-b17a-6d4eb66738aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedBN(global_model, clients, clientOpt, serverOpt, rounds=50, verb=True):\n",
    "    \n",
    "    # datastructure to keep in memory local bn statistics.\n",
    "    clients_local_bn_stats = {\n",
    "        client.name: {\n",
    "            param_name: params for param_name, params in client.model.state_dict().items() if 'bn' in param_name\n",
    "        } for client in clients\n",
    "    }\n",
    "    \n",
    "    total_samples = sum([len(client.dataset) for client in clients])\n",
    "    clients_samples = {client.name : len(client.dataset) for client in clients}\n",
    "\n",
    "    for round in range(rounds):\n",
    "        if verb:\n",
    "            print(f'Round {round+1}')\n",
    "\n",
    "        # local deltas\n",
    "        clients_delta = {\n",
    "            client.name : {\n",
    "                name : torch.zeros_like(params) for name, params in global_model.state_dict().items() if 'bn' not in name\n",
    "            } for client in clients\n",
    "        } \n",
    "        \n",
    "        for client in clients:\n",
    "            # load global model and previous round's local bn statistics.\n",
    "            client.model.load_state_dict(global_model.state_dict(), strict=False) \n",
    "            client.model.state_dict().update(clients_local_bn_stats[client.name])  \n",
    "\n",
    "            clientOpt.step(client.model, client.dataset, verb=verb)\n",
    "           \n",
    "            # save local bn stats \n",
    "            for name, stats in client.model.state_dict().items():\n",
    "                if 'bn' in name: \n",
    "                    clients_local_bn_stats[client.name][name].copy_(stats)\n",
    "            \n",
    "            # local changes, bn layers are excluded\n",
    "            for name in client.model.state_dict().keys():\n",
    "                if 'bn' not in name:\n",
    "                    delta = client.model.state_dict()[name] - global_model.state_dict()[name]\n",
    "                    clients_delta[client.name][name] = delta\n",
    "        \n",
    "        aggregated_delta = {name : torch.zeros_like(params, device='cpu') for name, params in global_model.state_dict().items() if 'bn' not in name}\n",
    "        \n",
    "        # aggregate local changes.\n",
    "        for client_name, local_delta in clients_delta.items():\n",
    "            for param_name in local_delta.keys():\n",
    "                tmp =  (local_delta[param_name] * clients_samples[client_name] / total_samples)\n",
    "                tmp = tmp.to(aggregated_delta[param_name].dtype)\n",
    "                aggregated_delta[param_name] += tmp\n",
    "            \n",
    "        serverOpt.step(aggregated_delta, round+1)\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2cfa6ca2-7e54-4eaf-9ee0-e14f03a67dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Epoch [1/2], Loss: 2.2746\n",
      "Epoch [2/2], Loss: 2.1991\n",
      "Epoch [1/2], Loss: 2.2926\n",
      "Epoch [2/2], Loss: 2.2515\n",
      "Round 2\n",
      "Epoch [1/2], Loss: 2.1930\n",
      "Epoch [2/2], Loss: 2.0727\n",
      "Epoch [1/2], Loss: 2.2581\n",
      "Epoch [2/2], Loss: 2.1980\n",
      "Round 3\n",
      "Epoch [1/2], Loss: 2.0834\n",
      "Epoch [2/2], Loss: 1.9611\n",
      "Epoch [1/2], Loss: 2.2192\n",
      "Epoch [2/2], Loss: 2.1555\n",
      "Round 4\n",
      "Epoch [1/2], Loss: 1.9867\n",
      "Epoch [2/2], Loss: 1.8786\n",
      "Epoch [1/2], Loss: 2.1875\n",
      "Epoch [2/2], Loss: 2.1218\n",
      "Round 5\n",
      "Epoch [1/2], Loss: 1.9116\n",
      "Epoch [2/2], Loss: 1.8231\n",
      "Epoch [1/2], Loss: 2.1589\n",
      "Epoch [2/2], Loss: 2.0877\n",
      "Round 6\n",
      "Epoch [1/2], Loss: 1.8590\n",
      "Epoch [2/2], Loss: 1.7826\n",
      "Epoch [1/2], Loss: 2.1270\n",
      "Epoch [2/2], Loss: 2.0520\n",
      "Round 7\n",
      "Epoch [1/2], Loss: 1.8207\n",
      "Epoch [2/2], Loss: 1.7548\n",
      "Epoch [1/2], Loss: 2.0929\n",
      "Epoch [2/2], Loss: 2.0187\n",
      "Round 8\n",
      "Epoch [1/2], Loss: 1.7920\n",
      "Epoch [2/2], Loss: 1.7331\n",
      "Epoch [1/2], Loss: 2.0603\n",
      "Epoch [2/2], Loss: 1.9898\n",
      "Round 9\n",
      "Epoch [1/2], Loss: 1.7704\n",
      "Epoch [2/2], Loss: 1.7176\n",
      "Epoch [1/2], Loss: 2.0302\n",
      "Epoch [2/2], Loss: 1.9648\n",
      "Round 10\n",
      "Epoch [1/2], Loss: 1.7529\n",
      "Epoch [2/2], Loss: 1.7034\n",
      "Epoch [1/2], Loss: 2.0042\n",
      "Epoch [2/2], Loss: 1.9431\n",
      "client1 acc : 65, client2 acc : 71\n"
     ]
    }
   ],
   "source": [
    "_, client1_acc, client2_acc = exp(FedBN, ServerSGD, verb=True, local_epochs=2, rounds=10, client_lr=0.001, server_lr=1)\n",
    "print(f'client1 acc : {client1_acc}, client2 acc : {client2_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4404188e-aa45-4333-8b8b-f7db1c2ae416",
   "metadata": {},
   "source": [
    "Some improvments for client2, but still slow convergence..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df7d9ba-0ffc-4120-a75b-4d3e1de85059",
   "metadata": {},
   "source": [
    "# ServerOpts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed4782b-a7d3-4ece-acf4-a7ee6a47b499",
   "metadata": {},
   "source": [
    "As mentioned previously, `FedOpt` allows the use of gradient-descent-based optimizers on the server side. Until now, we have used approaches with the server learning rate set to 1, analogous to `FedAvg`. Due to local batch normalization statistics, server optimization with a learning rate different from 1 was complex, but with the previously discussed batch normalization strategies, we can now use optimizers on the server side!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec960dc-0c7f-4b07-8471-6986139d63fc",
   "metadata": {},
   "source": [
    "![ServerOpts](figs/AdaptativeFed.png \"Adaptative Federated Optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5ba45e-17d9-4e23-9f0b-992b74e69a54",
   "metadata": {},
   "source": [
    " Here are the optimizers mentioned in Adaptative Federated Optimization, including additional bias correction for `Yogi`and `Adam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91dd8ea7-f9e2-48d7-a595-036486752fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServerAdagrad(ServerOpt):\n",
    "    def __init__(self, model, lr=0.01, beta_1=0.9, tau=0.0001):\n",
    "        super().__init__(model, lr)\n",
    "        self.beta_1 = beta_1\n",
    "        self.tau = tau\n",
    "\n",
    "        self.mt = {name: torch.zeros_like(param) for name, param in model.state_dict().items()}\n",
    "        self.vt = {name: torch.zeros_like(param) for name, param in model.state_dict().items()}\n",
    "        \n",
    "    def step(self, aggregated_delta, t=None):\n",
    "        for param_name, delta in aggregated_delta.items():\n",
    "            self.mt[param_name] = self.beta_1 * self.mt[param_name] + (1 - self.beta_1) * delta\n",
    "            self.vt[param_name] += delta**2\n",
    "            \n",
    "            adjusted_lr = self.lr / (torch.sqrt(self.vt[param_name]) + self.tau)\n",
    "            self.model.state_dict()[param_name].add_(adjusted_lr * self.mt[param_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9af459a9-c873-4e36-b25a-fd59089372d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServerYogi(ServerOpt):\n",
    "    def __init__(self, model, lr=0.01, beta_1=0.9, beta_2=0.99, tau=0.0001):\n",
    "        super().__init__(model, lr)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.tau = tau\n",
    "        \n",
    "        self.mt = {name: torch.zeros_like(param) for name, param in model.state_dict().items()}\n",
    "        self.vt = {name: torch.zeros_like(param) for name, param in model.state_dict().items()}\n",
    "\n",
    "    def step(self, aggregated_delta, t=None):\n",
    "        for param_name, delta in aggregated_delta.items():\n",
    "            self.mt[param_name] = self.beta_1 * self.mt[param_name] + (1 - self.beta_1) * delta\n",
    "            self.vt[param_name] -= (1 - self.beta_2) * delta**2 * torch.sign(self.vt[param_name] - delta**2)\n",
    "\n",
    "            # bias correction\n",
    "            mt_hat = self.mt[param_name] / (1 - self.beta_1**t)\n",
    "            vt_hat = self.vt[param_name] / (1 - self.beta_2**t)\n",
    "            \n",
    "            adjusted_lr = self.lr / (torch.sqrt(self.vt[param_name]) + self.tau)\n",
    "            self.model.state_dict()[param_name].add_(adjusted_lr * self.mt[param_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4a357d40-33ad-4c9e-b106-c593d6aabd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServerAdam(ServerOpt):\n",
    "    def __init__(self, model, lr=0.01, beta_1=0.9, beta_2=0.99, tau=0.0001):\n",
    "        super().__init__(model, lr)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.tau = tau\n",
    "        \n",
    "        self.mt = {name: torch.zeros_like(param) for name, param in model.state_dict().items()}\n",
    "        self.vt = {name: torch.zeros_like(param) for name, param in model.state_dict().items()}\n",
    "\n",
    "    def step(self, aggregated_delta, t=None):\n",
    "        for param_name, delta in aggregated_delta.items():\n",
    "            self.mt[param_name] = self.beta_1 * self.mt[param_name] + (1 - self.beta_1) * delta\n",
    "            self.vt[param_name] = self.beta_2 * self.vt[param_name] + (1 - self.beta_2) * delta**2  \n",
    "\n",
    "            # bias correction\n",
    "            mt_hat = self.mt[param_name] / (1 - self.beta_1**t)\n",
    "            vt_hat = self.vt[param_name] / (1 - self.beta_2**t)\n",
    "            \n",
    "            adjusted_lr = self.lr / (torch.sqrt(vt_hat) + self.tau)\n",
    "            self.model.state_dict()[param_name].add_(adjusted_lr * mt_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ee1382-1736-4b81-9387-164082f17860",
   "metadata": {},
   "source": [
    "What happens if we apply those optimizers with a strategy that handles batch-norm  ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3d778ba2-4db3-4bcc-a66e-02b1b6774c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Epoch [1/2], Loss: 2.2780\n",
      "Epoch [2/2], Loss: 2.1982\n",
      "Epoch [1/2], Loss: 2.2836\n",
      "Epoch [2/2], Loss: 2.2419\n",
      "Round 2\n",
      "Epoch [1/2], Loss: 2.0158\n",
      "Epoch [2/2], Loss: 1.9306\n",
      "Epoch [1/2], Loss: 2.1311\n",
      "Epoch [2/2], Loss: 2.0536\n",
      "Round 3\n",
      "Epoch [1/2], Loss: 1.8562\n",
      "Epoch [2/2], Loss: 1.8014\n",
      "Epoch [1/2], Loss: 2.0157\n",
      "Epoch [2/2], Loss: 1.9664\n",
      "Round 4\n",
      "Epoch [1/2], Loss: 1.7722\n",
      "Epoch [2/2], Loss: 1.7312\n",
      "Epoch [1/2], Loss: 1.9529\n",
      "Epoch [2/2], Loss: 1.9200\n",
      "Round 5\n",
      "Epoch [1/2], Loss: 1.7117\n",
      "Epoch [2/2], Loss: 1.6833\n",
      "Epoch [1/2], Loss: 1.9067\n",
      "Epoch [2/2], Loss: 1.8800\n",
      "Round 6\n",
      "Epoch [1/2], Loss: 1.6668\n",
      "Epoch [2/2], Loss: 1.6503\n",
      "Epoch [1/2], Loss: 1.8648\n",
      "Epoch [2/2], Loss: 1.8400\n",
      "Round 7\n",
      "Epoch [1/2], Loss: 1.6380\n",
      "Epoch [2/2], Loss: 1.6259\n",
      "Epoch [1/2], Loss: 1.8231\n",
      "Epoch [2/2], Loss: 1.7994\n",
      "Round 8\n",
      "Epoch [1/2], Loss: 1.6183\n",
      "Epoch [2/2], Loss: 1.6087\n",
      "Epoch [1/2], Loss: 1.7782\n",
      "Epoch [2/2], Loss: 1.7580\n",
      "Round 9\n",
      "Epoch [1/2], Loss: 1.6096\n",
      "Epoch [2/2], Loss: 1.5992\n",
      "Epoch [1/2], Loss: 1.7356\n",
      "Epoch [2/2], Loss: 1.7199\n",
      "Round 10\n",
      "Epoch [1/2], Loss: 1.6013\n",
      "Epoch [2/2], Loss: 1.5933\n",
      "Epoch [1/2], Loss: 1.6989\n",
      "Epoch [2/2], Loss: 1.6884\n",
      "client1 acc : 84, client2 acc : 85\n"
     ]
    }
   ],
   "source": [
    "_, client1_acc, client2_acc = exp(FedBN, ServerYogi, verb=True, local_epochs=2, rounds=10, client_lr=0.001, server_lr=0.01)\n",
    "print(f'client1 acc : {client1_acc}, client2 acc : {client2_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c040dc-19bb-40e8-8dca-168a9bc40cdf",
   "metadata": {},
   "source": [
    "Way better ! Let's try all of them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7ef5f6be-dcf4-46e3-93cb-34ff2b4cf7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adagrad</th>\n",
       "      <th>Yogi</th>\n",
       "      <th>Adam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SiloBN</th>\n",
       "      <td>(68, 77)</td>\n",
       "      <td>(85, 85)</td>\n",
       "      <td>(84, 86)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedBN</th>\n",
       "      <td>(70, 78)</td>\n",
       "      <td>(85, 83)</td>\n",
       "      <td>(82, 85)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Adagrad      Yogi      Adam\n",
       "SiloBN  (68, 77)  (85, 85)  (84, 86)\n",
       "FedBN   (70, 78)  (85, 83)  (82, 85)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algs = [SiloBN, FedBN] \n",
    "opts = [ServerAdagrad, ServerYogi, ServerAdam] \n",
    "\n",
    "alg_names = ['SiloBN', 'FedBN']\n",
    "opt_names = ['Adagrad', 'Yogi', 'Adam']\n",
    "\n",
    "df = pd.DataFrame(index=alg_names, columns=opt_names, dtype=object)\n",
    "\n",
    "for alg, alg_name in zip(algs, alg_names):\n",
    "    for opt, opt_name in zip(opts, opt_names):\n",
    "        _, client1_acc, client2_acc = exp(alg, opt, verb=False, local_epochs=2, rounds=10, client_lr=0.001, server_lr=0.01)\n",
    "        \n",
    "        df.at[alg_name, opt_name] = (client1_acc, client2_acc)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fafda09-af21-467c-86c5-c649826788a4",
   "metadata": {},
   "source": [
    "ServerYogi and ServerAdam produced significantly better results. While it is clear that the prior experiments could have achieved similar outcomes with appropriate tuning of local epochs, rounds, and client/server learning rates, we maintained consistent parameters across experiments to display and fairly compare different strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7e774a-5e9b-4abf-b2b3-c5ba13f27930",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d11309-da9d-4e96-be52-221bf72d1799",
   "metadata": {},
   "source": [
    "[A Field Guide to Federated Optimization, Jianyu Wang et al. 2021](https://arxiv.org/abs/2107.06917)\n",
    "\n",
    "[Siloed federated learning for multi-centric histopathology datasets, Andreux et al. 2020](https://arxiv.org/abs/2008.07424)\n",
    "\n",
    "[Adaptive federated optimization, Reddi et al. 2020](https://arxiv.org/abs/2003.00295)\n",
    "\n",
    "[FedBN: Federated Learning on Non-IID Features via Local Batch Normalization, Li et al. 2021](https://arxiv.org/abs/2102.07623)\n",
    "\n",
    "[Communication-efficient learning of deep networks from decentralized data, McMahan et al. 2023](https://arxiv.org/abs/1602.05629)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a381b-aba5-4eb3-afc6-a169dcbb465b",
   "metadata": {},
   "source": [
    "## Full derivations of (1) and (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc7bccb-462d-42ac-ab57-07aa5060b76a",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    x_{t+1} & = \\frac{1}{|\\mathcal{S}|} \\sum_{i \\in \\mathcal{S}} x_i^t = x_t - \\frac{1}{|\\mathcal{S}|} \\sum_{i \\in \\mathcal{S}} (x_t - x_i^t) \\\\\n",
    "            & =  x_t - \\frac{1}{|\\mathcal{S}|} (\\sum_{i \\in \\mathcal{S}} x_t - \\sum_{i \\in \\mathcal{S}} x_i^t) \\\\\n",
    "            & = x_t - \\frac{1}{|\\mathcal{S}|} \\left( |\\mathcal{S}| x_t - \\sum_{i \\in \\mathcal{S}} x_i^t \\right) \\\\\n",
    "            & = x_t - x_t + \\frac{1}{|\\mathcal{S}|} \\sum_{i \\in \\mathcal{S}} x_i^t \\\\\n",
    "            & = \\frac{1}{|\\mathcal{S}|} \\sum_{i \\in \\mathcal{S}} x_i^t\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e795b5ea-fad6-43f1-9453-a1fec4371c99",
   "metadata": {},
   "source": [
    "**Weighted average case** : \n",
    "\n",
    "let $p_i = \\sum_{i \\in \\mathcal{D}_{\\mathcal{S}_i}} x_i$ and $m_t = \\sum_{i \\in \\mathcal{S}_i} p_i$. And FedAvg : \n",
    "\n",
    "\\begin{align*}\n",
    "    x_{t+1} =  \\frac{\\sum_{i \\in \\mathcal{S}} p_i}{m_t} x_i^t\n",
    "\\end{align*}\n",
    "\n",
    "Then FedOpt: \n",
    "\n",
    "\\begin{align*}\n",
    "    x_{t+1} & = x_t + \\frac{\\sum_{i \\in \\mathcal{S}} p_i \\Delta_i^t}{m_t} \\\\\n",
    "            & = x_t + \\frac{\\sum_{i \\in \\mathcal{S}} p_i (x_i^t - x_t)}{m_t}\\\\\n",
    "            & = x_t + \\frac{1}{m_t} (\\sum_{i \\in \\mathcal{S}} p_i x_i^t - \\sum_{i \\in \\mathcal{S}} p_i x_t))\\\\\n",
    "            & = x_t + \\frac{1}{m_t} (\\sum_{i \\in \\mathcal{S}} p_i x_i^t - m_t \\times x_t))\\\\\n",
    "            & = \\frac{\\sum_{i \\in \\mathcal{S}} p_i }{m_t} x_i^t \\\\\n",
    "\\end{align*}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
